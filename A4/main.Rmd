---
title: "BT5152 A4"
author: "LI LIPING"
date: "17 October 2018"
output: html_document
---
Assignment 4 (Due 4th Nov 2018 5:59 PM )
###TASK 1
Conduct all relevant data-preprocessing of your textual data (TED Talk Transcripts).You need to describe your steps and processes taken. You may pre-process your dataset once and used it for all the following 3 tasks. [3 marks]
```{r}
set.seed(5152)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
trans <- read.csv('transcripts.csv', stringsAsFactors = FALSE)
main <- read.csv('ted_main.csv', stringsAsFactors = FALSE)
ted <- merge(trans,main,by.x = "url",by.y = "url")

library(tm)
doc_ids <- c(1:2467)
df <- data.frame(doc_id = doc_ids, text = trans$transcript, stringsAsFactors = FALSE)
transcripts <- VCorpus(DataframeSource(df))
# Convert the text to lower case
transcripts <- tm_map(transcripts, content_transformer(tolower))
# Remove numbers
transcripts <- tm_map(transcripts, removeNumbers)
# Remove english common stopwords
transcripts <- tm_map(transcripts, removeWords, stopwords('english'))
# Remove punctuations
transcripts <- tm_map(transcripts, removePunctuation)
# Eliminate extra white spaces
transcripts <- tm_map(transcripts, stripWhitespace)
#stem our words
transcripts <- tm_map(transcripts, stemDocument)
#Create a simple term frequency based DocumentTermMatrix on train_neg as tf_dtm
tf_dtm <- DocumentTermMatrix(transcripts)
```
###TASK 2
Using the dictionary approach, determine the emotions that are associated with the
talks by counting the occurrences of the emotions terms. [3 marks]
The final deliverable for this task is a heatmap with one axis as emotions and the other as the talks. The colour of the heatmap will show the count of the emotions.
You can expect it to be very dense and you might not want to show the label for the talks. This visualisation basically helps us to understand what kind of emotions are in the talks.
```{r}
set.seed(5152)
#obtain the sentiment data from General Inquirer
#install.packages("tm.lexicon.GeneralInquirer", repos="http://datacube.wu.ac.at", type="source")
require("tm.lexicon.GeneralInquirer")

#construct a data frame to save all the scores
emotion_df <- setNames(as.data.frame(matrix(nrow = 2467, ncol = 6)),c('emotion','active','strong','positive','pleasure','arousal'))

#store the emotion score in the General Inquirer
emotions <- terms_in_General_Inquirer_categories("EMOT")
emotion_df$emotion <- tm_term_score(tf_dtm, emotions)

active <- terms_in_General_Inquirer_categories("Active")
emotion_df$active <- tm_term_score(tf_dtm, active)

strong <- terms_in_General_Inquirer_categories("Strong")
emotion_df$strong <- tm_term_score(tf_dtm, strong)

positive <- terms_in_General_Inquirer_categories("Positiv")
emotion_df$positive <- tm_term_score(tf_dtm, positive)

pleasure <- terms_in_General_Inquirer_categories("Pleasur")
emotion_df$pleasure <- tm_term_score(tf_dtm, pleasure)

arousal <- terms_in_General_Inquirer_categories("Arousal")
emotion_df$arousal <- tm_term_score(tf_dtm, arousal)

# plot the heatmap
heatmap(as.matrix(emotion_df))
``` 
###TASK 3
Text Classification: using an appropriate algorithm you deem appropriate, perform a
multi-class classification on the ratings on the talks to predict how the talks will likely to get what rating from the viewers. [3 marks]
For this task, you should evaluate your model based on metrics such as micro and macro F1 and describe what are the common ratings that are misclassified in your model.
Notes:
1. You will need to replace single quote with double for ratings column before using jsonlite to parse it.
2. Use the rating with the highest count as the label for each talk. In other words, you are predicting a categorical variable, NOT a numerical variable such as average rating.
```{r}
set.seed(5152)
library(jsonlite)
library(caret)
#replace single quote with double for ratings column
ted$ratings <- gsub("\'","\"", ted$ratings)

#Use the rating with the highest count as the label for each talk
for (i in 1:nrow(ted)){
 ted$rating_mode[i] <- fromJSON(ted$ratings[i])$name[which.max(fromJSON(ted$ratings[i])$count)]}

#set an indexed type metadata called rating_mode
meta(transcripts, "rating_mode", type = "indexed") <- ted$rating_mode
#obtain the labels of corpus
label <- as.factor(meta(transcripts)$rating_mode)
#Create DocumentTermMatrix named tf_dtm with transcripts with control
dtm_control <- list(weighting = weightTf)
tf_dtm <- DocumentTermMatrix(transcripts, control = dtm_control)
#make use of words with high frequencies (> 10) as features to the classifier
freq_terms <- findFreqTerms(tf_dtm, lowfreq = 10)
#limit the terms in DocumentTermMatrix to just only these high frequency terms
dtm_control$dictionary <- freq_terms
#re-create tf_dtm with the amended dtm_control
tf_dtm2 <- DocumentTermMatrix(transcripts, control = dtm_control)

#Create a variable features_df to store tf_dtm in data frame
features_df <- tbl_df(data.frame(as.matrix(tf_dtm2)))
#remove columns with near zero variance with nearZeroVar function
nzv_columns <- nearZeroVar(features_df)
#remove all the columns from features_df that has near zero variance
features_df <- features_df[, -nzv_columns]

#seperate the train and test data
train_idx <- 1:round( 0.8*nrow(tf_dtm) )

#construct the model
ctrl <- trainControl(method = "cv", number = 5)
model <- train(features_df[train_idx,],label[train_idx], method = "C5.0", trControl = ctrl)

#check the predictions of the training data
pred <- predict(model$finalModel, features_df[-train_idx,],type="class")

#evaluate the performance by micro and macro F1
library(performanceEstimation)
classificationMetrics(pred,label[-train_idx])
confusionMatrix(pred,label[-train_idx])
```
According to the confusion matrix, we can find that Beautiful,Courageous,Fascinating,Funny,Ingenious,Jaw-dropping,Persuasive are the common ratings that are misclassified in my model


###TASK 4
Using topic modelling, find the top 10 related talks given a specific talk. You can think of this as sort of related articles feature that is common in many media sites. [3 marks]
You are to show a list of 10 articles for any specified article; you can show a few that have similarity above 0.5. Besides that you should also show your methodology (quantitatively or qualitatively) to derive the optimal topic model and justify your judgement.
Common notes for all tasks For consistency purpose, at the beginning of your script set the random seed to 5152.
```{r}
set.seed(5152)
library(topicmodels)
library(ggplot2)
library(dplyr)
library(tidytext)
library(lsa)

# separate the data to train and held-out dataset
train <- tf_dtm[train_idx,]
test <- tf_dtm[-train_idx,]

# Parallel Processing to train multiple LDA models
library(parallel)
library(doParallel)

# Create cluster to run R in parallel; best to use total number of CPU - 1
cl <- makePSOCKcluster(detectCores() - 1)

# Allow libraries such as doParallel and tm to access the cluster
registerDoParallel(cl)

# We are going to train models from 20 to 60 in step of 20
ks <- seq(20,60,20)

# Use parSapply to pass in additional parameters to LDA
models <- parSapply(cl = cl, ks,function(k, data) topicmodels::LDA(data, k = k, method = "Gibbs", control = list(iter = 100)),data = train)

# We use the held-out dataset to compute perplexity
# Explain perplexity
perplexities <- parSapply(cl = cl, models,function(m, data) topicmodels::perplexity(m, data, use_theta = TRUE, estimate_theta = TRUE),data = test)

# Getting the index of the model with the lowest perplexity
optimal_idx <- which.min(perplexities)

# the prob distribution of all document in each topic using the optimal model
topic_dist <- posterior(models[[optimal_idx]], tf_dtm)
stopCluster(cl)

#calculate the cosine similarity between every two document
topic_prob <- t(topic_dist$topics)
cosine_similarity <- cosine(topic_prob)

## find top 10 related ted talks, put them into related_talks
related_talks <- setNames(as.data.frame(matrix(nrow = 2467, ncol = 11)),c("original_talk","1","2","3","4","5","6","7","8","9","10"))
related_talks$original_talk <- ted$title
#put the top 10 largest cosine similarity in the data frame
r <- nrow(related_talks)
for (i in 1:r){
  #get the index of the top 10 related talks excerpt for itself(top 1)
  col_idx <- order(cosine_similarity[,i],decreasing = TRUE)[2:11]
  related_talks[i,-1] <- as.character(ted$title[col_idx])
}
#have a look at the data frame
head(related_talks)
```
